PAM (Plan Applier Mechanism) is a program that understands stories by analyzing the intentions of the story's characters, and relating their intentions to their actions. PAM reads in sentences in English, produces Conceptual Dependency (CD) meaning representations for them, and connects together Lhese CD's to form a
story representation.

While scripts can be used to understand very familiar situations, plans are needed to understand novel ones.

"PAM has a great deal of knowledge about people's goals, and applies this knowledge to find explanations for the actions taken by a stoy's characters in term of that character's goals and plans.

"The story reader's main job is to understand the goals of each character in the story

Uses ELI to parse the sentence into CD.

## Request

In addition to having this knowledge of plans, goals, and themes, an understander must have some way of applying its knowledge to an understanding task. PAM applies its knowledge through the use of requests. A request is an "expectation" coupled together with an action to be taken if the expectation is met. 

## Goal

A single agent may have multiple goals in story. These often conflict.
One agent may help another agent towards his goal.

## Plan

The plan starts with a main goal. This goal depends on sub-goals: I-goals (instrumental) and D-goals (delta). 

* I goal: I-PREP, I-COOK (a realization of I-PREP)
* D goal: D-PROX, D-KNOW, D-CONTROL
* Planbox: ASK, OVERPOWER, THREATEN, BARGAIN, INGEST. A planbox has preconditions and a result.

A named plan is a fixed sequence of instrumental goals that form the usual path to the attainment of a goal. Example:

    USE(X) = D-KNOW(LOC(X)) + D-PROX(X) + D-CONT(X) + I-PREP(X) + DO

## Main loop

PAM's control structure had a main loop that reacted to each input sentence by classifying it as either a goal or an action. For every action, PAM would try to find a plan it could be part of, such that that plan could be explained as arising from a known goal.


## Understanding

The story can contain a goal explicitly, or the understander infers the goal. Then the understander decomposes this goal into sub-goals. The means to achieve a goal is called a plan-box.

At any point in reading a story PAM has a list of predicted plan-boxes. If a new sentence fits a plan box, it is said to be understood.

Understanding is a combination of bottom-up and top-down. Bottom-up can make generic inferences, while top-down can make predictions.

* Explicit goals: "John wanted money"
* From an action, infer a goal: "John got a gun" => "John want a gun"
* From a goal infer possible super-goals: "John want a gun" => "John want to overpower / threathen someone"
* From an action, infer part of a plan: "and walked into a liquor store" => activate plan to rob store

goal: want money; plan: rob store; plan parts: go to store, threaten employee, take money

"Story understanding is explanation-driven"

Types of explanation:
- intentional: event => plan, plan => goal, goal => theme
- causal

## Papers

* Recognizing plans summarizing actions - Schmidt et al (1976)
* Using plans to understand natural language - Wilensky (1976)
* PAM - a program that infers intentions - Wilensky (1977)
* Understanding Goal-Based Stories (PhD thesis) - Wilensky (1978)
* Memory and inference - Wilensky (1983)

## Notes

- maybe the extra semantic information provided in CD statements can be invoked only when needed, like when an explanation is sought; this would simplify the grammar 
- implementing predictions as "demons" (a separate process or thread?) seems odd; just use a stored data structure?
